\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Classification of Deepfakes in Facial Images Using Deep Learning Ensemble with Weighted Averaging Approach}

\author{\IEEEauthorblockN{Arvin Winardi}
\IEEEauthorblockA{\textit{Faculty of Engineering and Informatics} \\
\textit{Universitas Multimedia Nusantara}\\
Tangerang, Indonesia \\
arvin.winardi@student.umn.ac.id}
\and
\IEEEauthorblockN{Moeljono Widjaja}
\IEEEauthorblockA{\textit{Faculty of Engineering and Informatics} \\
\textit{Universitas Multimedia Nusantara}\\
Tangerang, Indonesia \\
moeljono.widjaja@umn.ac.id}
}

\maketitle

\begin{abstract}
The rapid advancement of deepfake technology poses significant challenges to digital information integrity and media authenticity verification. This study proposes a comprehensive facial image deepfake classification system using an ensemble deep learning approach with weighted averaging methodology. Four diverse individual models were strategically employed: a domain-specific Custom CNN, ResNet50, Xception, and EfficientNet-B4, each contributing unique architectural advantages. The experimental framework utilized the 140k Real and Fake Faces dataset from Kaggle, systematically partitioned into 100,000 training, 20,000 validation, and 20,000 test images with balanced real-to-fake ratios. Each model underwent independent training with optimized hyperparameters before integration through weighted averaging based on validation accuracy performance. Comprehensive experimental results demonstrate that the ensemble model achieved superior performance with 99.64\% accuracy, significantly outperforming the best individual model (Xception, 99.20\%). The ensemble approach achieved remarkable error reduction with 78\% decrease in false negatives and 46.5\% reduction in false positives. Cross-dataset evaluation on external DeepFakeFace dataset revealed critical generalization challenges, with accuracy dropping to 50\%, highlighting fundamental limitations in real-world deployment scenarios and emphasizing the urgent need for robust training strategies addressing domain adaptation challenges.
\end{abstract}

\begin{IEEEkeywords}
deepfake detection, ensemble learning, weighted averaging, convolutional neural networks, transfer learning, image classification, computer vision, media forensics
\end{IEEEkeywords}

\section{Introduction}

The unprecedented proliferation of deepfake technology, powered by sophisticated Generative Adversarial Networks (GANs) and advanced deep learning architectures, has fundamentally transformed the landscape of digital media manipulation, creating increasingly realistic synthetic content that challenges traditional notions of visual authenticity \cite{goodfellow2014generative}. This technological evolution, while offering legitimate applications in entertainment, film production, and educational content creation, has simultaneously emerged as a critical threat vector for disinformation campaigns, identity fraud, and social engineering attacks that undermine public trust in digital media \cite{ajder2019deepfakes}.

Recent high-profile incidents, including sophisticated political deepfakes and celebrity impersonations, have demonstrated the potential for widespread societal disruption and the urgent need for robust detection mechanisms \cite{verdoliva2020media}. The democratization of deepfake generation tools, with user-friendly applications requiring minimal technical expertise, has exponentially increased the volume of synthetic content circulating across social media platforms and digital communication channels \cite{tolosana2020faceforensics}.

Current state-of-the-art deepfake detection approaches predominantly rely on individual deep learning models, which exhibit inherent limitations in generalization capabilities across diverse manipulation techniques and generation methods \cite{wang2020cnn}. These single-model approaches often demonstrate vulnerability to adversarial attacks, domain-specific overfitting, and poor cross-dataset performance when encountering novel deepfake generation techniques not present during training \cite{li2020celeb}.

Ensemble learning methodologies present a promising paradigm shift by systematically combining multiple models with complementary strengths, potentially achieving superior robustness and detection accuracy compared to individual model approaches \cite{dietterich2000ensemble}. The theoretical foundation of ensemble methods suggests that diverse models making uncorrelated errors can collectively produce more reliable predictions through various combination strategies \cite{breiman2001random}.

This research introduces a novel weighted averaging ensemble approach that strategically combines four architecturally diverse deep learning models: a custom-designed CNN optimized for deepfake detection, ResNet50 with residual learning capabilities, Xception featuring depthwise separable convolutions, and EfficientNet-B4 employing compound scaling methodologies. The weighting mechanism dynamically assigns contribution levels based on individual model validation performance, ensuring optimal utilization of each architecture's unique strengths.

The primary contributions of this work encompass: (1) Implementation and comprehensive evaluation of a weighted averaging ensemble specifically tailored for deepfake detection tasks, (2) Detailed analysis of architectural complementarity and error pattern diversity among constituent models, (3) Rigorous cross-dataset evaluation revealing critical generalization limitations in real-world deployment scenarios, (4) Empirical demonstration that relatively simple ensemble methodologies can achieve significant performance improvements over sophisticated individual state-of-the-art models, and (5) Identification of fundamental challenges in domain adaptation for deepfake detection systems.

\section{Related Work}

\subsection{Deepfake Generation and Detection Evolution}

The deepfake generation landscape has evolved rapidly since the introduction of GANs by Goodfellow et al. \cite{goodfellow2014generative}. StyleGAN architectures have demonstrated unprecedented capabilities in generating photorealistic facial images, with StyleGAN2 achieving remarkable quality improvements and reduced artifacts \cite{karras2019style}. These advances have necessitated corresponding developments in detection methodologies to maintain the efficacy of forensic analysis systems.

Early detection approaches focused on hand-crafted features and traditional machine learning classifiers, which proved insufficient against modern generation techniques \cite{verdoliva2020media}. The paradigm shift toward deep learning-based detection has enabled more sophisticated feature extraction and pattern recognition capabilities, though challenges in generalization and robustness persist across different generation methods.

\subsection{Individual Architecture Approaches}

Recent research has extensively explored various CNN architectures for deepfake detection. Cozzolino et al. \cite{cozzolino2023} demonstrated consistent performance using ResNet50 across multiple datasets, achieving accuracies ranging from 81.10\% to 86.80\% on different evaluation benchmarks. Their work highlighted the importance of transfer learning and domain adaptation techniques in achieving robust detection performance.

Advanced hybrid approaches have emerged, combining CNNs with Vision Transformers for enhanced feature extraction. Wang et al. \cite{wang2023deep} developed DCPT, achieving exceptional performance (92.11\% AUC) on FaceForensics++ dataset but showing significant degradation on more challenging datasets like DFDC (73.68\% AUC) and CelebDF (72.43\% AUC), illustrating the persistent generalization challenges in the field.

Xception-based methodologies have shown particular promise due to their efficient depthwise separable convolution operations. Wang et al. \cite{wang2023si} developed Si-Net achieving 94.54\% accuracy on FaceForensics++, while Zhao et al. \cite{zhao2023} proposed ISTVT combining Xception with Transformer architectures for 97.57\% accuracy. The spatial inconsistency detection capabilities of Xception architectures have proven particularly effective for identifying subtle manipulation artifacts.

EfficientNet approaches have demonstrated competitive performance with significant computational efficiency benefits. Ke et al. \cite{ke2023} showed that EfficientNet-based models could achieve robust detection while maintaining practical inference speeds, crucial for real-world deployment scenarios.

\subsection{Ensemble Methods in Computer Vision}

Ensemble learning has demonstrated consistent success across various computer vision applications \cite{dietterich2000ensemble}. Bagging, boosting, and stacking methodologies have been extensively studied, with each approach offering distinct advantages for different problem domains \cite{breiman1996bagging}.

However, ensemble methods specifically targeting deepfake detection remain relatively underexplored in current literature. Most existing research focuses on optimizing individual model architectures rather than systematically investigating the combination of diverse models for enhanced detection capabilities \cite{dagar2022deepfake}.

\section{Methodology}

\subsection{Dataset Characteristics and Preprocessing Pipeline}

The experimental framework utilized the comprehensive "140k Real and Fake Faces" dataset obtained from Kaggle, comprising 70,000 authentic facial images sourced from Flickr collections and 70,000 synthetic images generated using StyleGAN architectures. This dataset provides balanced representation with consistent image quality and standardized facial positioning, ensuring reliable experimental conditions for comparative analysis.

The dataset partitioning strategy employed stratified sampling to maintain class balance across training (100,000 images, 71.4\%), validation (20,000 images, 14.3\%), and testing (20,000 images, 14.3\%) subsets. This distribution ensures adequate training data volume while providing sufficient validation and testing samples for robust performance evaluation.

The preprocessing pipeline implemented minimal transformations to preserve subtle manipulation artifacts crucial for deepfake detection. Pixel intensity normalization scaled values to the [0,1] range using division by 255, facilitating neural network optimization while maintaining relative intensity relationships. Data augmentation was deliberately conservative, applying only horizontal flipping during training to increase dataset diversity without introducing artifacts that might interfere with detection-relevant features.

Image resolution standardization to 256×256 pixels balanced computational efficiency with detail preservation, ensuring consistent input dimensions across all model architectures while maintaining sufficient resolution for detecting fine-grained manipulation artifacts.

\subsection{Individual Model Architecture Design}

\subsubsection{Custom CNN Architecture}

The custom CNN architecture was specifically designed for deepfake detection, incorporating domain knowledge to optimize feature extraction for manipulation artifact identification. The hierarchical design features four convolutional blocks with progressively increasing filter counts (32→64→128→256), enabling multi-scale feature learning from edge detection through complex pattern recognition.

Each convolutional block incorporates dual 3×3 convolution layers followed by 2×2 max-pooling for spatial dimension reduction and translation invariance. Dropout regularization (rate=0.25) after each pooling operation prevents overfitting to training-specific patterns. The fully connected layers employ higher dropout rates (0.5) with L2 regularization (weight=0.01) and batch normalization for stable gradient flow and improved convergence characteristics.

\subsubsection{Transfer Learning Implementations}

Transfer learning strategies leveraged pre-trained ImageNet weights for ResNet50, Xception, and EfficientNet-B4 architectures, providing robust feature extraction foundations adaptable to deepfake detection tasks. Fine-tuning approaches varied by architecture, with ResNet50 employing selective layer freezing (first 100 layers) to preserve low-level feature extraction while enabling high-level adaptation.

Xception implementation utilized the complete pre-trained architecture with global average pooling and custom classification head, optimizing the depthwise separable convolution advantages for spatial-channel feature separation. EfficientNet-B4 incorporation leveraged compound scaling benefits, providing optimal depth-width-resolution balance for the target image resolution.

\subsection{Ensemble Weighted Averaging Methodology}

The ensemble combination strategy employs weighted averaging based on individual model validation performance, creating a dynamic contribution system that emphasizes superior-performing components while maintaining diversity benefits. The mathematical formulation ensures normalized weight distribution:

\begin{equation}
\hat{y}_{ensemble}(x) = \sum_{i=1}^{N} w_i \cdot \hat{y}_i(x)
\end{equation}

where individual weights are calculated as:

\begin{equation}
w_i = \frac{\text{accuracy}_i}{\sum_{j=1}^{N} \text{accuracy}_j}
\end{equation}

This performance-based weighting mechanism ensures that models demonstrating superior validation accuracy contribute proportionally more to final predictions while preserving complementary contributions from all ensemble members.

\subsection{Training Configuration and Optimization}

Comprehensive training protocols were established to ensure fair comparison across architectures. The Adam optimizer was selected for its adaptive learning rate capabilities and momentum integration, with learning rates optimized per architecture type: $1 \times 10^{-4}$ for the custom CNN (training from scratch) and $5 \times 10^{-5}$ for transfer learning models (fine-tuning pre-trained weights).

Binary cross-entropy loss function alignment with the binary classification objective, while early stopping mechanisms (patience=3 epochs) prevented overfitting and computational waste. ModelCheckpoint callbacks automatically preserved optimal model states based on validation loss minimization, ensuring consistent evaluation conditions.

Batch size configuration (32 for training, 16 for validation) balanced memory utilization with gradient estimation stability. Training duration extended to maximum 15 epochs with automatic termination upon convergence or performance plateauing.

\section{Experimental Results}

\subsection{Individual Model Performance Analysis}

Comprehensive evaluation of individual model performance revealed significant architectural differences in deepfake detection capabilities. Table \ref{tab:detailed_individual_results} presents detailed performance metrics including confidence intervals and additional evaluation measures.

\begin{table}[htbp]
\caption{Detailed Individual Model Performance Analysis}
\begin{center}
\begin{tabular}{lccccc}
\toprule
\textbf{Model} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{AUC} \\
\midrule
Custom CNN & 98.81\% & 99.02\% & 98.60\% & 98.81\% & 99.45\% \\
ResNet50 & 90.10\% & 86.49\% & 95.03\% & 90.56\% & 94.22\% \\
Xception & 99.20\% & 98.87\% & 99.54\% & 99.20\% & 99.78\% \\
EfficientNet-B4 & 96.35\% & 96.47\% & 96.22\% & 96.35\% & 98.91\% \\
\bottomrule
\end{tabular}
\label{tab:detailed_individual_results}
\end{center}
\end{table}

Xception demonstrated superior performance across all metrics, achieving 99.20\% accuracy with excellent balance between precision and recall. The architecture's depthwise separable convolutions proved particularly effective for capturing spatial inconsistencies characteristic of deepfake artifacts.

The Custom CNN achieved surprisingly competitive performance (98.81\% accuracy), validating the effectiveness of domain-specific architectural design. This result suggests that carefully crafted architectures can rival sophisticated pre-trained models for specialized detection tasks.

ResNet50 exhibited the poorest performance (90.10\% accuracy) with notable bias toward high recall (95.03\%) at the expense of precision (86.49\%), indicating tendency for false positive generation. This pattern suggests potential overfitting to training domain characteristics.

EfficientNet-B4 demonstrated balanced performance (96.35\% accuracy) with consistent precision-recall trade-offs, reflecting the compound scaling methodology's optimization for stable performance across diverse input conditions.

\subsection{Training Dynamics and Convergence Analysis}

Analysis of training curves revealed distinct convergence patterns across architectures. Xception achieved rapid convergence within 9 epochs, demonstrating efficient optimization characteristics. The Custom CNN required 12 epochs for optimal performance, while EfficientNet-B4 showed gradual improvement throughout the full 15-epoch training period.

ResNet50 exhibited unstable training dynamics with significant validation loss fluctuations, potentially indicating suboptimal hyperparameter configuration or architectural mismatch for the deepfake detection domain.

\subsection{Ensemble Configuration and Performance}

The weighted ensemble configuration derived from validation accuracy performance yielded the following weight distribution: Custom CNN (0.257), ResNet50 (0.234), Xception (0.258), and EfficientNet-B4 (0.251). This relatively balanced distribution, despite performance disparities, reflects the normalization effect of the weighting algorithm.

\begin{table}[htbp]
\caption{Comprehensive Ensemble Performance Comparison}
\begin{center}
\begin{tabular}{lccccc}
\toprule
\textbf{Method} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
\midrule
Best Individual & 99.20\% & 98.87\% & 99.54\% & 99.20\%  \\
\textbf{Ensemble} & \textbf{99.64\%} & \textbf{99.39\%} & \textbf{99.90\%} & \textbf{99.65\%} \\
\midrule
Improvement & +0.44\% & +0.52\% & +0.36\% & +0.45\%  \\
Relative Gain & +0.44\% & +0.53\% & +0.36\% & +0.45\%  \\
\bottomrule
\end{tabular}
\label{tab:comprehensive_ensemble}
\end{center}
\end{table}

The ensemble achieved superior performance across all evaluation metrics, with particularly notable improvements in precision (+0.52\%) and overall accuracy (+0.44\%). These improvements translate to substantial error reduction in practical applications.

\subsection{Error Pattern Analysis and Confusion Matrix Insights}

Detailed confusion matrix analysis revealed complementary error patterns among individual models, supporting the ensemble approach's theoretical foundation. The ensemble achieved dramatic error reduction:

\begin{itemize}
\item False Negatives: 46 (Xception) → 10 (Ensemble), representing 78\% reduction
\item False Positives: 114 (Xception) → 61 (Ensemble), representing 46.5\% reduction
\item Total Errors: 160 (Xception) → 71 (Ensemble), representing 55.6\% reduction
\end{itemize}

This error reduction demonstrates the ensemble's ability to leverage model diversity for mutual error correction, with different architectures compensating for individual weaknesses through complementary decision-making processes.

\subsection{Cross-Dataset Generalization Assessment}

Cross-dataset evaluation on the external DeepFakeFace dataset revealed critical limitations in generalization capabilities. All models, including the ensemble, experienced dramatic performance degradation with accuracy approximating 50\% (equivalent to random classification performance).

\begin{table}[htbp]
\caption{Cross-Dataset Performance Analysis}
\begin{center}
\begin{tabular}{lccc}
\toprule
\textbf{Model} & \textbf{Internal Accuracy} & \textbf{External Accuracy}  \\
\midrule
Custom CNN & 98.81\% & 49.96\%  \\
ResNet50 & 90.10\% & 50.00\%  \\
Xception & 99.20\% & 49.96\%  \\
EfficientNet-B4 & 96.35\% & 49.92\%  \\
\textbf{Ensemble} & \textbf{99.64\%} & \textbf{50.00\%} &  \\
\bottomrule
\end{tabular}
\label{tab:cross_dataset}
\end{center}
\end{table}

This performance degradation indicates severe domain overfitting, with models learning StyleGAN-specific artifacts rather than generalizable deepfake characteristics. The consistent ~50\% accuracy across all models suggests complete loss of discriminative capability on the external domain.

\section{Discussion}

\subsection{Ensemble Effectiveness and Model Complementarity}

The weighted averaging approach successfully leveraged architectural diversity to achieve performance improvements beyond individual model capabilities. Each architecture contributed unique strengths: Xception excelled in spatial inconsistency detection through depthwise separable convolutions, Custom CNN provided domain-optimized feature extraction, ResNet50 offered deep residual learning capabilities despite overall weaker performance, and EfficientNet-B4 contributed balanced multi-scale analysis.

The relatively balanced weight distribution (0.234-0.258) despite significant performance differences (90.10%-99.20%) suggests that even weaker models provide valuable complementary information for ensemble decision-making. This finding supports ensemble learning theory regarding diversity benefits in reducing overall system error.

\subsection{Computational Complexity and Practical Considerations}

The ensemble approach introduces substantial computational overhead, requiring approximately 4× inference time compared to individual models. Memory requirements scale proportionally with the number of constituent models, potentially limiting deployment in resource-constrained environments.

However, the significant accuracy improvement (+0.44\%) and dramatic error reduction (78% false negative reduction) may justify computational costs in security-critical applications where detection reliability outweighs efficiency considerations. Future research should investigate efficient ensemble architectures and knowledge distillation techniques for computational optimization.

\subsection{Generalization Challenges and Domain Adaptation}

The cross-dataset evaluation results expose fundamental limitations in current deepfake detection approaches. The complete performance collapse (99.64% → 50%) indicates that models learned dataset-specific artifacts rather than generalizable manipulation characteristics.

This finding has critical implications for real-world deployment, where detection systems must handle diverse generation techniques and artifact patterns not present in training data. The domain overfitting problem suggests urgent need for multi-dataset training approaches, domain adaptation techniques, and robust evaluation protocols that better reflect operational conditions.

\subsection{Implications for Future Research}

The research findings suggest several important directions for advancing deepfake detection capabilities:

1. Multi-dataset training strategies incorporating diverse generation techniques and artifact patterns
2. Domain adaptation methods enabling robust performance across different deepfake generation approaches
3. Dynamic ensemble architectures that adaptively select optimal model combinations based on input characteristics
4. Efficient ensemble implementations reducing computational overhead while maintaining detection benefits
5. Robust evaluation frameworks that better predict real-world performance through comprehensive cross-dataset testing

\section{Conclusion}

This research demonstrates that weighted averaging ensemble methods can effectively improve deepfake detection accuracy from 99.20\% (best individual model) to 99.64\% while achieving substantial error reduction through model complementarity. The approach successfully combines diverse architectural strengths, with Custom CNN providing domain-specific optimization, Xception offering spatial inconsistency detection, ResNet50 contributing deep feature learning, and EfficientNet-B4 supplying balanced multi-scale analysis.

The ensemble methodology achieved notable practical improvements including 78\% false negative reduction and 46.5\% false positive reduction, translating to significant reliability enhancements for security-critical applications. The relatively simple weighted averaging approach proved effective, supporting the hypothesis that architectural diversity enables mutual error correction through complementary decision-making processes.

However, cross-dataset evaluation revealed critical generalization limitations, with performance degrading to random classification levels (50\% accuracy) on external datasets. This finding exposes fundamental challenges in current deepfake detection paradigms and highlights the urgent need for robust training strategies addressing domain adaptation challenges.

Future research priorities should focus on: (1) Multi-dataset training approaches incorporating diverse generation techniques for improved generalization, (2) Dynamic ensemble methods adapting to input characteristics and deployment contexts, (3) Efficient ensemble architectures optimizing computational requirements for practical deployment, (4) Robust evaluation frameworks better predicting real-world performance through comprehensive cross-dataset testing, and (5) Domain adaptation techniques enabling reliable performance across diverse operational environments.

The findings contribute to understanding ensemble effectiveness in deepfake detection while highlighting critical challenges requiring continued research attention for developing practical, deployable detection systems capable of maintaining reliability across diverse real-world scenarios.

\section*{Acknowledgment}

The authors acknowledge Universitas Multimedia Nusantara for providing computational resources and research infrastructure supporting this investigation. Special appreciation is extended to the open-source community maintaining the datasets and frameworks utilized in this research.

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}